{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\"\n",
    "     align=\"right\"\n",
    "     width=\"30%\"\n",
    "     alt=\"Dask logo\\\">\n",
    "\n",
    "# DASK : a flexible library for parallel computing in Python.\n",
    "\n",
    "### 1. Dask supports the Pandas dataframe and Numpy array data structures\n",
    "### 2. Dask cab be run on your local computer or be scaled up to run on a cluster (code to be written just once)\n",
    "### 3. With minimal code changes, you can run code in parallel taking advantage of the processing power already on your laptop\n",
    "\n",
    "\n",
    "If you love Pandas and Numpy but were sometimes struggling with data that would not fit into RAM then Dask is definitely what you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSTALLATION\n",
    "### CONDA \n",
    "Usually dask gets installed with your Anaconda. You can update Dask using the conda command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!conda install dask #This installs Dask and all common dependencies, including Pandas and NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIP\n",
    "\n",
    "You can install everything required for most common uses of Dask (arrays, dataframes, …) This installs both Dask and dependencies like NumPy, Pandas, and so on that are necessary for different workloads. This is often the right choice for Dask users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install \"dask[complete]\"    # Installs everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelize code with `dask.delayed`\n",
    "\n",
    "In this section we parallelize simple for-loop style code with Dask and `dask.delayed`.\n",
    "\n",
    "This is a simple way to use `dask` to parallelize existing codebases or build [complex systems](http://matthewrocklin.com/blog/work/2018/02/09/credit-models-with-dask).  This will also help us to develop an understanding for later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def inc(x):\n",
    "    sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    sleep(1)\n",
    "    return x + y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.8 ms, total: 2.8 ms\n",
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This takes three seconds to run because we call each\n",
    "# function sequentially, one after the other\n",
    "\n",
    "x = inc(1)\n",
    "y = inc(2)\n",
    "z = add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelize with the `dask.delayed` decorator\n",
    "\n",
    "Those two increment calls *could* be called in parallel.\n",
    "\n",
    "We'll wrap the `inc` and `add` functions in the `dask.delayed` decorator. When we call the delayed version by passing the arguments, the original function isn't actually called yet.\n",
    "Instead, a *task graph* is built up, representing the *delayed* function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 982 µs, sys: 791 µs, total: 1.77 ms\n",
      "Wall time: 4.63 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This runs immediately, all it does is build a graph\n",
    "\n",
    "x = delayed(inc)(1)\n",
    "y = delayed(inc)(2)\n",
    "z = delayed(add)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('add-d81d2826-ecfc-4ce8-8c9c-920e6969379a')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ran immediately, since nothing has really happened yet.\n",
    "\n",
    "To get the result, call `compute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.18 ms, sys: 7.58 ms, total: 16.8 ms\n",
      "Wall time: 2.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# This actually runs our computation using a local thread pool\n",
    "\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What just happened?\n",
    "\n",
    "The `z` object is a lazy `Delayed` object.  This object holds everything we need to compute the final result.  We can compute the result with `.compute()` as above or we can visualize the task graph for this value with `.visualize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install python-graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the task graph for `z`\n",
    "z.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Parallelizing a for-loop code with control flow\n",
    "\n",
    "Often we want to delay only *some* functions, running a few of them immediately.  This is especially helpful when those functions are fast and help us to determine what other slower functions we should call.  This decision, to delay or not to delay, is usually where we need to be thoughtful when using `dask.delayed`.\n",
    "\n",
    "In the example below we iterate through a list of inputs.  If that input is even then we want to call `inc`.  If the input is odd then we want to call `double`.  This `is_even` decision to call `inc` or `double` has to be made immediately (not lazily) in order for our graph-building Python code to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double(x):\n",
    "    sleep(1)\n",
    "    return 2 * x\n",
    "\n",
    "def is_even(x):\n",
    "    return not x % 2\n",
    "\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Sequential code\n",
    "\n",
    "results = []\n",
    "for x in data:\n",
    "    if is_even(x):\n",
    "        y = double(x)\n",
    "    else:\n",
    "        y = inc(x)\n",
    "    results.append(y)\n",
    "    \n",
    "total = sum(results)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Your parallel code here...\n",
    "# TODO: parallelize the sequential code above using dask.delayed\n",
    "# You will need to delay some functions, but not all\n",
    "\n",
    "results = []\n",
    "for x in data:\n",
    "    if is_even(x):  # even\n",
    "        y = delayed(double)(x)\n",
    "    else:          # odd\n",
    "        y = delayed(inc)(x)\n",
    "    results.append(y)\n",
    "    \n",
    "total = delayed(sum)(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time total.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing a Pandas Groupby Reduction\n",
    "\n",
    "In this exercise we read several CSV files and perform a groupby operation in parallel.  We are given sequential code to do this and parallelize it with `dask.delayed`.\n",
    "\n",
    "The computation we will parallelize is to compute the mean departure delay per airport from some historical flight data.  We will do this by using `dask.delayed` together with `pandas`.  In a future section we will do this same exercise with `dask.dataframe`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/data/export/DataScience_Notebooks/Dask'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '1990.csv',\n",
       " '1991.csv',\n",
       " '1992.csv',\n",
       " '1993.csv',\n",
       " '1994.csv',\n",
       " '1995.csv',\n",
       " '1996.csv',\n",
       " '1997.csv',\n",
       " '1998.csv',\n",
       " '1999.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "sorted(os.listdir('Data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(os.path.join('C:\\\\Users\\\\sharvik\\\\data', 'nycflights', '1990.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the schema?\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential code: Mean Departure Delay Per Airport\n",
    "The above cell computes the mean departure delay per-airport for one year. Here we expand that to all years using a sequential for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "filenames = sorted(glob(os.path.join('C:\\\\Users\\\\sharvik\\\\data', 'nycflights', '*.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sums = []\n",
    "counts = []\n",
    "for fn in filenames:\n",
    "    # Read in file\n",
    "    df = pd.read_csv(fn)\n",
    "    \n",
    "    # Groupby origin airport\n",
    "    by_origin = df.groupby('Origin')\n",
    "    \n",
    "    # Sum of all departure delays by origin\n",
    "    total = by_origin.DepDelay.sum()\n",
    "    \n",
    "    # Number of flights by origin\n",
    "    count = by_origin.DepDelay.count()\n",
    "    \n",
    "    # Save the intermediates\n",
    "    sums.append(total)\n",
    "    counts.append(count)\n",
    "\n",
    "# Combine intermediates to get total mean-delay-per-origin\n",
    "total_delays = sum(sums)\n",
    "n_flights = sum(counts)\n",
    "mean = total_delays / n_flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelize the code above\n",
    "Use dask.delayed to parallelize the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sums = []\n",
    "counts = []\n",
    "for fn in filenames:\n",
    "    # Read in file\n",
    "    df = delayed(pd.read_csv)(fn)\n",
    "    \n",
    "    # Groupby origin airport\n",
    "    by_origin = df.groupby('Origin')\n",
    "    \n",
    "    # Sum of all departure delays by origin\n",
    "    total = by_origin.DepDelay.sum()\n",
    "    \n",
    "    # Number of flights by origin\n",
    "    count = by_origin.DepDelay.count()\n",
    "    \n",
    "    # Save the intermediates\n",
    "    sums.append(total)\n",
    "    counts.append(count)\n",
    "\n",
    "### Delayed Objects\n",
    "sout = sums\n",
    "cout = counts\n",
    "\n",
    "sums, counts = compute(sums, counts)\n",
    "# Combine intermediates to get total mean-delay-per-origin\n",
    "total_delays = sum(sums)\n",
    "n_flights = sum(counts)\n",
    "mean = total_delays / n_flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cout[0].visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
